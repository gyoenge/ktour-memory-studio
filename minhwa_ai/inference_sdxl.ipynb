{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22d507b",
   "metadata": {},
   "source": [
    "### Text-to-image LoRA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d608b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "lora_model_path = \"./sdxl-lora-minhwa-style\" # set your LoRA model path\n",
    "pipe.load_lora_weights(lora_model_path)\n",
    "\n",
    "prompt = (\n",
    "    \"Korean traditional minhwa painting, \"\n",
    "    \"two person, \"\n",
    "    \"a men wearing Korean hat, gat, blue clothes, \"\n",
    "    \"a men wearing blue clothes, \"\n",
    "    \"with a background of green mountain landscape.\"\n",
    ") # set your prompt\n",
    "image = pipe(prompt=prompt, num_inference_steps=30).images[0]\n",
    "\n",
    "image.save(\"minhwa_test_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9336fc",
   "metadata": {},
   "source": [
    "### ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "\n",
    "# --- 1. Base 모델 및 Refiner 모델 불러오기 ---\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "refiner_model_id = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "device = \"cuda\"\n",
    "\n",
    "# Base 모델 로드\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safensors=True\n",
    ").to(device)\n",
    "\n",
    "# Refiner 모델 로드\n",
    "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    refiner_model_id,\n",
    "    text_encoder_2=pipe.text_encoder_2,\n",
    "    vae=pipe.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safensors=True,\n",
    "    variant=\"fp16\",\n",
    ").to(device)\n",
    "\n",
    "# --- 2. 학습된 LoRA 가중치 적용 ---\n",
    "lora_model_path = \"./sdxl-lora-minhwa-style-2\"\n",
    "pipe.load_lora_weights(lora_model_path)\n",
    "# Refiner에도 동일한 LoRA를 적용할 수 있습니다 (선택사항, 스타일에 따라 효과가 다름)\n",
    "# refiner.load_lora_weights(lora_model_path)\n",
    "\n",
    "\n",
    "# --- 3. 프롬프트 및 고급 설정 ---\n",
    "prompt = (\n",
    "    \"masterpiece, best quality, \"\n",
    "    \"Korean traditional minhwa painting, \"\n",
    "    \"two person, \"\n",
    "    \"a man wearing Korean hat, gat, elegant blue clothes, \"\n",
    "    \"a woman wearing traditional hanbok, \"\n",
    "    \"with a beautiful background of green mountain landscape and pine trees.\"\n",
    ")\n",
    "\n",
    "negative_prompt = (\n",
    "    \"blurry, low quality, worst quality, ugly, deformed, distorted, \"\n",
    "    \"watermark, signature, text, jpeg artifacts, poorly drawn\"\n",
    ")\n",
    "\n",
    "# Refiner를 사용할 때 Base 모델이 어느 정도까지만 디노이징할지 설정\n",
    "# 0.8은 80% 지점까지만 Base가 작업하고 나머지 20%는 Refiner에게 넘긴다는 의미\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "# --- 4. 이미지 생성 (Base -> Refiner) ---\n",
    "print(\"이미지 생성을 시작합니다 (Base -> Refiner)...\")\n",
    "\n",
    "# Base 모델 실행, output_type=\"latent\"로 설정하여 Refiner에 넘길 잠재 공간 이미지 생성\n",
    "latents = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=1216,\n",
    "    height=832,\n",
    "    num_inference_steps=40,\n",
    "    guidance_scale=8.0,\n",
    "    denoising_end=high_noise_frac, # Base 모델이 작업을 멈출 지점\n",
    "    output_type=\"latent\",\n",
    ").images[0]\n",
    "\n",
    "# Refiner 모델 실행, Base에서 받은 latents를 image 인자로 넘김\n",
    "image = refiner(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=40,\n",
    "    guidance_scale=8.0,\n",
    "    denoising_start=high_noise_frac, # Refiner 모델이 작업을 시작할 지점\n",
    "    image=latents,\n",
    ").images[0]\n",
    "\n",
    "\n",
    "# --- 5. 이미지 저장 ---\n",
    "image.save(\"minhwa_test_high_quality.png\")\n",
    "print(\"고품질 이미지가 'minhwa_test_high_quality.png'으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd268ab1",
   "metadata": {},
   "source": [
    "## Add Textual Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "\n",
    "# --- 1. 모델 및 가중치 경로 설정 ---\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "refiner_model_id = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "lora_model_path = \"./sdxl-lora-minhwa-style-2\"\n",
    "textual_inversion_path = \"./textual_inversion_korean_house\"\n",
    "device = \"cuda\"\n",
    "\n",
    "# --- 2. 베이스 모델 로드 ---\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safensors=True\n",
    ").to(device)\n",
    "\n",
    "# --- 3. 학습된 LoRA 가중치 적용 ---\n",
    "pipe.load_lora_weights(lora_model_path)\n",
    "print(\"LoRA 가중치를 적용했습니다.\")\n",
    "\n",
    "# --- 4. 학습된 Textual Inversion 임베딩 적용 ---\n",
    "pipe.load_textual_inversion(textual_inversion_path)\n",
    "print(\"Textual Inversion 임베딩을 적용했습니다.\")\n",
    "\n",
    "# --- 5. Refiner 모델 로드 ---\n",
    "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    refiner_model_id,\n",
    "    text_encoder_2=pipe.text_encoder_2,\n",
    "    vae=pipe.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safensors=True,\n",
    "    variant=\"fp16\",\n",
    ").to(device)\n",
    "print(\"Refiner 모델을 로드했습니다.\")\n",
    "\n",
    "\n",
    "# --- 6. 프롬프트 및 고급 설정 ---\n",
    "# LoRA 스타일과 Textual Inversion placeholder token(<korean-house>)을 모두 사용\n",
    "prompt = (\n",
    "    \"masterpiece, best quality, \"\n",
    "    \"Korean traditional minhwa painting, \"\n",
    "    \"<korean-house>.\" # <-- 학습한 placeholder token 사용\n",
    ")\n",
    "\n",
    "negative_prompt = (\n",
    "    \"blurry, low quality, worst quality, ugly, deformed, distorted, \"\n",
    "    \"watermark, signature, text, jpeg artifacts, poorly drawn\"\n",
    ")\n",
    "\n",
    "# Refiner를 사용할 때 Base 모델이 어느 정도까지만 디노이징할지 설정\n",
    "# 0.8은 80% 지점까지만 Base가 작업하고 나머지 20%는 Refiner에게 넘긴다는 의미\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "\n",
    "# --- 7. 이미지 생성 (Base -> Refiner) ---\n",
    "print(\"이미지 생성을 시작합니다 (Base -> Refiner)...\")\n",
    "\n",
    "# Base 모델 실행, output_type=\"latent\"로 설정하여 Refiner에 넘길 잠재 공간 이미지 생성\n",
    "latents = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=40,\n",
    "    guidance_scale=9.0,\n",
    "    denoising_end=high_noise_frac, # Base 모델이 작업을 멈출 지점\n",
    "    output_type=\"latent\",\n",
    ").images\n",
    "\n",
    "# Refiner 모델 실행, Base에서 받은 latents를 image 인자로 넘김\n",
    "image = refiner(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=40,\n",
    "    guidance_scale=8.0,\n",
    "    denoising_start=high_noise_frac, # Refiner 모델이 작업을 시작할 지점\n",
    "    image=latents,\n",
    ").images[0]\n",
    "\n",
    "\n",
    "# --- 8. 이미지 저장 ---\n",
    "image.save(\"minhwa_house_with_lora_ti_and_refiner.png\")\n",
    "print(\"고품질 이미지가 'minhwa_house_with_lora_ti_and_refiner.png'으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3e6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
